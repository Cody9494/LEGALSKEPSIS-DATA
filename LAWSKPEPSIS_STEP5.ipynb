{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNb7HPWxxQgVXJERfmh/CWw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cody9494/LEGALSKEPSIS-DATA/blob/main/LAWSKPEPSIS_STEP5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-OJkaw8dHr7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNPNXVrTG8ES"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Φόρτωση του dataset με τα embeddings\n",
        "df_chunks = pd.read_parquet(\"/content/drive/MyDrive/LAWSKEPSIS/df_chunks_with_embeddings.parquet\")\n",
        "\n",
        "# Εξασφάλιση ότι τα embeddings είναι tensor\n",
        "df_chunks[\"embedding\"] = df_chunks[\"embedding\"].apply(lambda x: torch.tensor(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer(\"intfloat/e5-mistral-7b-instruct\")\n"
      ],
      "metadata": {
        "id": "LAmftk4vHpOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_chunks"
      ],
      "metadata": {
        "id": "iR5YEJsMICDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def semantic_search_grouped_by_act(query, model, df_chunks, top_k=5, aggregation=\"max\"):\n",
        "    # 1. Ενσωμάτωση ερωτήματος\n",
        "    query_emb = model.encode(query, convert_to_tensor=True, normalize_embeddings=True)\n",
        "\n",
        "    # 2. Πίνακας embeddings\n",
        "    all_embeddings = torch.stack(df_chunks[\"embedding\"].to_list()).to(query_emb.device)\n",
        "\n",
        "    # 3. Υπολογισμός cosine similarity\n",
        "    cosine_scores = F.cosine_similarity(query_emb.unsqueeze(0), all_embeddings)\n",
        "\n",
        "    df_chunks = df_chunks.copy()\n",
        "    df_chunks[\"similarity\"] = cosine_scores.cpu().numpy()\n",
        "\n",
        "    # 4. Ομαδοποίηση ανά act_id με aggregation\n",
        "    if aggregation == \"max\":\n",
        "        act_scores = df_chunks.groupby(\"act_id\")[\"similarity\"].max().reset_index()\n",
        "    elif aggregation == \"mean\":\n",
        "        act_scores = df_chunks.groupby(\"act_id\")[\"similarity\"].mean().reset_index()\n",
        "    elif aggregation == \"top3mean\":\n",
        "        act_scores = (\n",
        "            df_chunks.sort_values(\"similarity\", ascending=False)\n",
        "            .groupby(\"act_id\")\n",
        "            .head(3)\n",
        "            .groupby(\"act_id\")[\"similarity\"].mean()\n",
        "            .reset_index()\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(\"Unknown aggregation method\")\n",
        "\n",
        "    # 5. Επιλογή top-k act_id\n",
        "    top_acts = act_scores.sort_values(\"similarity\", ascending=False).head(top_k)\n",
        "\n",
        "    # 6. Ανάκτηση κορυφαίου chunk ανά act\n",
        "    result_chunks = (\n",
        "        df_chunks[df_chunks[\"act_id\"].isin(top_acts[\"act_id\"])]\n",
        "        .sort_values([\"act_id\", \"similarity\"], ascending=[True, False])\n",
        "        .groupby(\"act_id\")\n",
        "        .head(1)\n",
        "    )\n",
        "\n",
        "    return result_chunks[[\"act_id\", \"chunk_index\", \"chunk_text\", \"similarity\"]].reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "R5RL5TFNIlJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Αφαίρεση chunks με λίγους tokens\n",
        "df_filtered = df_chunks[df_chunks[\"token_len\"] > 30]\n",
        "\n",
        "\n",
        "# 3. Θορυβώδεις λέξεις-κλειδιά\n",
        "noise_keywords = [\"http\", \"www.\", \"europa.eu\", \"italic\", \"ELI:\", \"OJ L\", \"data.europa.eu\", \"screen/expert-groups\"]\n",
        "\n",
        "# 4. Υπολογισμός ποσοστού θορύβου ανά chunk\n",
        "def noise_ratio(text, noise_keywords):\n",
        "    words = text.split()\n",
        "    if not words:\n",
        "        return 1.0\n",
        "    noise_count = sum(any(kw.lower() in word.lower() for kw in noise_keywords) for word in words)\n",
        "    return noise_count / len(words)\n",
        "\n",
        "df_filtered[\"noise_ratio\"] = df_filtered[\"chunk_text\"].apply(lambda txt: noise_ratio(txt, noise_keywords))\n",
        "\n",
        "# 5. Φιλτράρισμα chunks με >30% θορυβώδεις λέξεις\n",
        "df_filtered = df_filtered[df_filtered[\"noise_ratio\"] < 0.3].reset_index(drop=True)\n",
        "\n",
        "# 6. Προβολή δείγματος\n",
        "import random\n",
        "sample = df_filtered.sample(3, random_state=42)\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "display(sample[[\"act_id\", \"chunk_index\", \"chunk_text\", \"token_len\", \"noise_ratio\"]])"
      ],
      "metadata": {
        "id": "maVnVZt5JaDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_filtered)"
      ],
      "metadata": {
        "id": "TN0LN0rDJpvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered"
      ],
      "metadata": {
        "id": "FiJxZoh7LxP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Can the EU freeze a person’s assets as part of sanctions?\"\n",
        "\n",
        "top_acts = semantic_search_grouped_by_act(\n",
        "    query,\n",
        "    model=model,\n",
        "    df_chunks=df_filtered,  # το noise-filtered df\n",
        "    top_k=5,\n",
        "    aggregation=\"max\",  # ή \"mean\", \"top3mean\"\n",
        ")\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "display(top_acts)\n"
      ],
      "metadata": {
        "id": "gVJIQOsiJnDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nsu5ToUvMSQX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}